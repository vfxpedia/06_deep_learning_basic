{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1be9478a",
   "metadata": {},
   "source": [
    "미분과 수치미분 개념\n",
    "\n",
    "**수학적 미분 (Analytical Differentiation)**\n",
    "\n",
    "$$\n",
    "f(x) = x^2 \\Rightarrow f'(x) = 2x\n",
    "$$\n",
    "\n",
    "* 수학적으로 정확한 **도함수**를 구함\n",
    "* 함수의 변화율을 계산하는 공식 기반 미분\n",
    "\n",
    "**수치미분 (Numerical Differentiation)**\n",
    "$$\n",
    "f'(x) \\approx \\frac{f(x+h) - f(x-h)}{2h}\n",
    "$$\n",
    "* 도함수를 직접 구하지 않고, **근사값으로 기울기를 계산**\n",
    "* 여기서 $h$는 아주 작은 수 (예: $h = 1e-4$)\n",
    "* 실제 계산 과정을 코드로 볼 수 있어 **직관적**\n",
    "\n",
    "**미분 vs 수치미분 비교표**\n",
    "\n",
    "| 항목    | 수학적 미분 (Analytical) | 수치미분 (Numerical)          |\n",
    "| ----- | ------------------- | ------------------------- |\n",
    "| 정의 방식 | 공식에 따라 도함수 계산       | 근사값으로 기울기 계산              |\n",
    "| 정확도   | 매우 정확함              | 근사값, 오차 발생 가능             |\n",
    "| 속도    | 빠름                  | 느림 (함수값 여러 번 계산 필요)       |\n",
    "| 용도    | 모델 학습, 역전파 계산       | 디버깅, 검증용 (Gradient Check) |\n",
    "\n",
    "**수치미분 방식비교**\n",
    "\n",
    "> 중앙차분(Central Difference) 방식이 가장 보편적으로 사용된다.\n",
    "\n",
    "| 방식   | 수식                                           | 정확도    | 계산 비용 | 특징         |\n",
    "| ---- | -------------------------------------------- | ------ | ----- | ---------- |\n",
    "| 전진차분 | $f'(x) \\approx \\frac{f(x+h) - f(x)}{h}$    | 1차 정확도 | 낮음    | 간단하지만 오차 큼 |\n",
    "| 후진차분 | $f'(x) \\approx \\frac{f(x) - f(x-h)}{h}$    | 1차 정확도 | 낮음    | 전진과 비슷     |\n",
    "| 중앙차분 | $f'(x) \\approx \\frac{f(x+h) - f(x-h)}{2h}$ | 2차 정확도 | 높음    | 정확하고 균형잡힘  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f538b5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65a43573",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 1차원 함수의 수치 미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60e94351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "수학적 미분 : 6\n",
      "전진 차분   : 6.000100000012054\n",
      "후진 차분   : 5.99990000001327\n",
      "중앙 차분   : 6.000000000012662\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return x**2\n",
    "\n",
    "def analytical_diff(x):\n",
    "    return 2*x\n",
    "\n",
    "def numerical_diff_forward(f, x, epsilon=1e-4):\n",
    "    return (f(x+epsilon) - f(x)) / epsilon\n",
    "\n",
    "def numerical_diff_backward(f, x, epsilon=1e-4):\n",
    "    return (f(x) - f(x-epsilon)) / epsilon\n",
    "\n",
    "def numerical_diff_central(f, x, epsilon=1e-4):\n",
    "    return (f(x+epsilon) - f(x-epsilon)) / (2*epsilon)\n",
    "\n",
    "x = 3\n",
    "\n",
    "print(f'수학적 미분 : {analytical_diff(x)}')\n",
    "print(f'전진 차분   : {numerical_diff_forward(f, x)}')\n",
    "print(f'후진 차분   : {numerical_diff_backward(f, x)}')\n",
    "print(f'중앙 차분   : {numerical_diff_central(f, x)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4090aef1",
   "metadata": {},
   "source": [
    "### 다변수 함수의 수치 미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cac8192c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f(x, y) = 13.0\n",
      "∂f/∂x = 6.000000000039306\n",
      "∂f/∂y = 4.000000000026205\n"
     ]
    }
   ],
   "source": [
    "def f(x, y):                  # 2차원 함수, 편미분 미분 필요 : 변수가 여러 개인 경우\n",
    "    return x**2 + y**2        # 하나의 변수는 고정하고 다른 변수의 변화량을 측정\n",
    "\n",
    "def partial_diff_x(f, x, y, var='x', h=1e-5):\n",
    "    if var == 'x':\n",
    "        return (f(x+h, y) - f(x-h, y)) / (2*h)\n",
    "    elif var == 'y':\n",
    "        return (f(x, y+h) - f(x, y-h)) / (2*h)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid variable: {var}\")\n",
    "\n",
    "x = 3.0\n",
    "y = 2.0\n",
    "\n",
    "print(f'f(x, y) = {f(x, y)}')\n",
    "print(f'∂f/∂x = {partial_diff_x(f, x, y, var='x')}')\n",
    "print(f'∂f/∂y = {partial_diff_x(f, x, y, var='y')}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c36ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "미분을 해서 변화량을 구해주는 것 = 기울기 구하는 내용용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb715c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 4. 6.]\n",
      "[2. 4. 6.]\n"
     ]
    }
   ],
   "source": [
    "### 다변수 함수의 수치 미분\n",
    "def f_multi(x):\n",
    "    return np.sum(x**2)\n",
    "\n",
    "def analytical_gradient(x):\n",
    "    return 2 * x\n",
    "\n",
    "# 수치 미분 함수를 기반으로 기울기 구하는 함수\n",
    "def num_d_gradient(f, x, h=1e-5):\n",
    "    grad = np.zeros_like(x)\n",
    "    for idx in range(len(x)):\n",
    "        tmp = x[idx]\n",
    "        x[idx] = tmp + h\n",
    "        f_plus = f(x)\n",
    "\n",
    "        x[idx] = tmp - h\n",
    "        f_minus = f(x)\n",
    "        \n",
    "        grad[idx] = (f_plus - f_minus) / (2 * h)\n",
    "        x[idx] = tmp\n",
    "    return grad\n",
    "\n",
    "x = np.array([1.0, 2.0, 3.0])\n",
    "print(analytical_gradient(x))\n",
    "print(num_d_gradient(f_multi, x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e78193b",
   "metadata": {},
   "source": [
    "### 간단한 신경망의 기울기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9b1e34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0번째 파라미터 수치 미분 기울기: \n",
      "[[-3.59076788e-04 -1.91454872e-04 -1.82558270e-03]\n",
      " [ 1.43630717e-04  7.65819482e-05  7.30233079e-04]]\n",
      "1번째 파라미터 수치 미분 기울기: \n",
      "[-0.00071815 -0.00038291 -0.00365117]\n",
      "2번째 파라미터 수치 미분 기울기: \n",
      "[[-0.00872872]\n",
      " [-0.00457938]\n",
      " [-0.00700196]]\n",
      "3번째 파라미터 수치 미분 기울기: \n",
      "[-0.01091606]\n"
     ]
    }
   ],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\"\"\"\n",
    "def sigmoid_derivative(z):\n",
    "    return sigmoid(z) * (1 - sigmoid(z))\n",
    "\n",
    "z = np.array([0.5, 0.8, -0.3])\n",
    "\n",
    "# 신경망 파라미터\n",
    "params = (np.array([0.1, 0.2, 0.3]), 0.1, np.array([0.4, 0.5, 0.6]), 0.2)\n",
    "\"\"\"\n",
    "# 신경망 전방 패스, 순전파\n",
    "def forward_pass(x, params):\n",
    "    W1, b1, W2, b2 = params\n",
    "    z1 = np.dot(x, W1) + b1\n",
    "    r1 = sigmoid(z1)\n",
    "    z2 = np.dot(r1, W2) + b2\n",
    "    r2 = sigmoid(z2)\n",
    "    return r2\n",
    "    \n",
    "def loss(r2, y):\n",
    "    return 0.5 * np.sum((r2 - y) ** 2)    # 예측값과 실제값의 차이를 제곱해서 평균을 구함, MSE 손실 함수\n",
    "\n",
    "def get_loss(params, x, y):\n",
    "    r2 = forward_pass(x, params)\n",
    "    return loss(r2, y)\n",
    "\n",
    "def num_d_gradient_params(f, params, x, y, h=1e-5):\n",
    "    grads = []\n",
    "\n",
    "    for param in params:\n",
    "        grad = np.zeros_like(param)\n",
    "        iter = np.nditer(param, flags=['multi_index'], op_flags=['readwrite'])\n",
    "\n",
    "        while not iter.finished:\n",
    "            idx = iter.multi_index\n",
    "            origin_val = param[idx]\n",
    "            param[idx] = origin_val + h\n",
    "            f_plus = f(params, x, y)\n",
    "            param[idx] = origin_val - h\n",
    "            f_minus = f(params, x, y)\n",
    "            grad[idx] = (f_plus - f_minus) / (2 * h)\n",
    "            param[idx] = origin_val\n",
    "            iter.iternext()\n",
    "\n",
    "        grads.append(grad)\n",
    "    return grads\n",
    "\n",
    "np.random.seed(0)\n",
    "input_size = 2\n",
    "hidden_size = 3\n",
    "output_size = 1\n",
    "\n",
    "W1 = np.random.randn(input_size, hidden_size)\n",
    "b1 = np.random.randn(hidden_size)\n",
    "W2 = np.random.randn(hidden_size, output_size)\n",
    "b2 = np.random.randn(output_size)\n",
    "params = [W1, b1, W2, b2]\n",
    "\n",
    "x = np.array([0.5, -0.2])\n",
    "y = np.array([1.0])\n",
    "\n",
    "num_grads = num_d_gradient_params(get_loss, params, x, y)\n",
    "\n",
    "for i, grad in enumerate(num_grads):\n",
    "    print(f'{i}번째 파라미터 수치 미분 기울기: \\n{grad}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d2ffe8",
   "metadata": {},
   "source": [
    "### h값에 따른 영향\n",
    "\n",
    "def f(x):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d32694",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
